{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c088d738",
   "metadata": {},
   "source": [
    "# **1. Perkenalan Dataset (Heart Disease / UCI)**\n",
    "Dataset: *Heart Disease* (berasal dari UCI Machine Learning Repository).\n",
    "\n",
    "**Tujuan**: memprediksi ada/tidaknya penyakit jantung berdasarkan fitur klinis.\n",
    "\n",
    "**Catatan label/target**:\n",
    "- Beberapa versi dataset memakai kolom `target` (0/1)\n",
    "- Versi UCI klasik memakai `num` (0–4). Biasanya dikonversi menjadi biner: `num>0` → 1 (disease)\n",
    "\n",
    "**Lokasi file** (disarankan):\n",
    "- Simpan CSV mentah di: `../namadataset_raw/heart.csv` atau `../namadataset_raw/heart_disease.csv`.\n",
    "\n",
    "Jika Anda menjalankan notebook ini di Kaggle/Colab tanpa internet, cukup **upload** file CSV ke folder tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3735cab3",
   "metadata": {},
   "source": [
    "Tahap pertama, pastikan Anda sudah memiliki dataset sesuai ketentuan (tabular, ada target, ukuran wajar)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df305bf0",
   "metadata": {},
   "source": [
    "# **2. Import Library**\n",
    "Di tahap ini kita impor library untuk data loading, EDA, dan preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97382f84",
   "metadata": {},
   "source": [
    "Library utama: `pandas`, `numpy`, `matplotlib`, dan `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939ca959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Supaya output rapi\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e702b977",
   "metadata": {},
   "source": [
    "# **3. Memuat Dataset**\n",
    "Kita coba cari file CSV di folder `namadataset_raw`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a4ff2",
   "metadata": {},
   "source": [
    "Jika nama file berbeda, silakan sesuaikan variabel `DATA_PATH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f86b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ganti sesuai file kamu (salah satu biasanya ada)\n",
    "CANDIDATE_PATHS = [\n",
    "    os.path.join(\"..\", \"namadataset_raw\", \"heart.csv\"),\n",
    "    os.path.join(\"..\", \"namadataset_raw\", \"heart_disease.csv\"),\n",
    "    os.path.join(\"..\", \"namadataset_raw\", \"dataset.csv\"),\n",
    "]\n",
    "\n",
    "DATA_PATH = None\n",
    "for p in CANDIDATE_PATHS:\n",
    "    if os.path.exists(p):\n",
    "        DATA_PATH = p\n",
    "        break\n",
    "\n",
    "if DATA_PATH is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"File dataset tidak ditemukan. Upload/letakkan CSV ke folder ../namadataset_raw/ \"\n",
    "        \"dengan nama: heart.csv atau heart_disease.csv\"\n",
    "    )\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"✅ Loaded:\", DATA_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda2fd26",
   "metadata": {},
   "source": [
    "# **4. Exploratory Data Analysis (EDA)**\n",
    "Tujuan EDA: memahami struktur data, cek missing value, cek distribusi target, dan ringkasan statistik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed5e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Struktur dasar\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.sample(5, random_state=42))\n",
    "\n",
    "print(\"\\nInfo:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "display(df.isna().sum().sort_values(ascending=False).head(20))\n",
    "\n",
    "print(\"\\nStatistik numerik:\")\n",
    "display(df.describe(include=[np.number]).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d2e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Deteksi kolom target (umum: 'target' atau 'num')\n",
    "possible_targets = [c for c in df.columns if c.lower() in [\"target\", \"num\", \"diagnosis\", \"label\"]]\n",
    "print(\"Kemungkinan kolom target:\", possible_targets)\n",
    "\n",
    "# Pilih prioritas: target > num\n",
    "target_col = None\n",
    "if \"target\" in df.columns:\n",
    "    target_col = \"target\"\n",
    "elif \"num\" in df.columns:\n",
    "    target_col = \"num\"\n",
    "elif len(possible_targets) > 0:\n",
    "    target_col = possible_targets[0]\n",
    "\n",
    "if target_col is None:\n",
    "    raise ValueError(\"Kolom target tidak ditemukan. Pastikan dataset punya label seperti 'target' atau 'num'.\")\n",
    "\n",
    "print(\"✅ target_col =\", target_col)\n",
    "\n",
    "# Lihat distribusi target\n",
    "display(df[target_col].value_counts(dropna=False).to_frame(\"count\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28692e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Visual sederhana (opsional tapi membantu reviewer)\n",
    "# Distribusi target (kalau num 0-4, tetap ditampilkan)\n",
    "plt.figure(figsize=(6,4))\n",
    "df[target_col].value_counts().sort_index().plot(kind=\"bar\")\n",
    "plt.title(\"Distribusi Target\")\n",
    "plt.xlabel(target_col)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c052be8",
   "metadata": {},
   "source": [
    "# **5. Data Preprocessing**\n",
    "Kita siapkan data agar siap dilatih:\n",
    "- Pisah fitur (X) dan label (y)\n",
    "- Tangani missing value\n",
    "- Encoding kategorikal (OneHot)\n",
    "- Scaling numerik\n",
    "- Split train/test\n",
    "- Simpan output ke folder `namadataset_preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057e6f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Pisah X & y\n",
    "X = df.drop(columns=[target_col]).copy()\n",
    "y_raw = df[target_col].copy()\n",
    "\n",
    "# Jika target berupa 0-4 (UCI 'num'), ubah ke biner (0 = no disease, >0 = disease)\n",
    "if y_raw.nunique() > 2:\n",
    "    y = (y_raw.astype(float) > 0).astype(int)\n",
    "    print(\"Target dikonversi ke biner dari\", target_col, \"(num>0 -> 1).\")\n",
    "else:\n",
    "    y = y_raw.astype(int)\n",
    "\n",
    "print(\"X shape:\", X.shape, \"| y shape:\", y.shape)\n",
    "print(\"Distribusi y (biner):\")\n",
    "display(pd.Series(y).value_counts().to_frame(\"count\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fc5a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Tentukan kolom numerik & kategorikal\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = [c for c in X.columns if c not in numeric_cols]\n",
    "\n",
    "print(\"Numeric cols:\", len(numeric_cols), numeric_cols[:10])\n",
    "print(\"Categorical cols:\", len(categorical_cols), categorical_cols[:10])\n",
    "\n",
    "# Pipeline preprocessing untuk masing-masing tipe data\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719210c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y if pd.Series(y).nunique() == 2 else None\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d528ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 Fit-transform data train, transform data test\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"X_train_proc shape:\", X_train_proc.shape)\n",
    "print(\"X_test_proc shape:\", X_test_proc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0446dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.5 Simpan hasil preprocessing\n",
    "# Kita simpan sebagai CSV siap latih:\n",
    "# - Karena setelah OneHot bentuknya bisa sparse, kita ubah ke array dense lalu jadi DataFrame.\n",
    "# - Nama kolom onehot diambil dari OneHotEncoder.\n",
    "\n",
    "# Ambil feature names\n",
    "feature_names = []\n",
    "if len(numeric_cols) > 0:\n",
    "    feature_names += numeric_cols\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    ohe = preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "    ohe_names = ohe.get_feature_names_out(categorical_cols).tolist()\n",
    "    feature_names += ohe_names\n",
    "\n",
    "def to_dense_df(X_proc, feature_names):\n",
    "    # Support sparse matrix\n",
    "    try:\n",
    "        X_dense = X_proc.toarray()\n",
    "    except Exception:\n",
    "        X_dense = np.asarray(X_proc)\n",
    "    return pd.DataFrame(X_dense, columns=feature_names)\n",
    "\n",
    "train_df = to_dense_df(X_train_proc, feature_names)\n",
    "train_df[\"label\"] = y_train.values\n",
    "\n",
    "test_df = to_dense_df(X_test_proc, feature_names)\n",
    "test_df[\"label\"] = y_test.values\n",
    "\n",
    "out_train = os.path.join(\"namadataset_preprocessing\", \"train_preprocessed.csv\")\n",
    "out_test  = os.path.join(\"namadataset_preprocessing\", \"test_preprocessed.csv\")\n",
    "\n",
    "train_df.to_csv(out_train, index=False)\n",
    "test_df.to_csv(out_test, index=False)\n",
    "\n",
    "print(\"✅ Saved:\", out_train, \"shape:\", train_df.shape)\n",
    "print(\"✅ Saved:\", out_test, \"shape:\", test_df.shape)\n",
    "train_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
